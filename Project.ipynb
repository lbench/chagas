{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1a8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from helper_code2 import *\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e0529",
   "metadata": {},
   "source": [
    "transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4da933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeOut:\n",
    "    \"\"\"Set random segment to 0. Expect Input is Tensor in (B,C,T) form. Output is Tensor in (B,C,T) form.\n",
    "    \"\"\"\n",
    "    def __init__(self, crop_ratio_range=[0.0, 0.5]):\n",
    "        self.crop_ratio_range = crop_ratio_range\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        data, label = sample\n",
    "        data = data.clone()\n",
    "        timesteps = data.shape[-1]\n",
    "        crop_ratio = random.uniform(*self.crop_ratio_range)\n",
    "        crop_timesteps = int(crop_ratio*timesteps)\n",
    "        start_idx = random.randint(0, timesteps - crop_timesteps-1)\n",
    "        if data.dim() == 3:\n",
    "            data[:, :, start_idx:start_idx+crop_timesteps] = 0\n",
    "        else:\n",
    "            data[:, start_idx:start_idx+crop_timesteps] = 0\n",
    "        return data, label\n",
    "    \n",
    "class RandomResizeCrop:\n",
    "    \"\"\"Random crop and resize to original size. Input is Tensor in (B,C,T) form. Output is Tensor in (B,C,T) form\n",
    "    \"\"\"\n",
    "    def __init__(self, crop_ratio_range=[0.5, 1.0], output_size=4096):\n",
    "        self.crop_ratio_range = crop_ratio_range\n",
    "        self.output_size=output_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        data, label = sample\n",
    "        timesteps = data.shape[-1]\n",
    "        crop_ratio = random.uniform(*self.crop_ratio_range)\n",
    "        crop_timesteps = int(crop_ratio*timesteps)\n",
    "        start = random.randint(0, timesteps - crop_timesteps-1)\n",
    "        if data.dim() == 3:\n",
    "            cropped_data = data[:, :, start: start + crop_timesteps]\n",
    "            resized = F.interpolate(cropped_data, size=self.output_size, mode='linear')\n",
    "            return resized, label\n",
    "        else:\n",
    "            cropped_data = data[:, start: start + crop_timesteps]\n",
    "            resized = F.interpolate(cropped_data.unsqueeze(0), size=self.output_size, mode='linear')\n",
    "            return resized.squeeze(), label\n",
    "    \n",
    "class RandomTransformation:\n",
    "    \"\"\"Generate augmentated data.\n",
    "    \"\"\"\n",
    "    def __init__(self, to_range=[0.0, 0.5], rrc_range=[0.5, 1.0]):\n",
    "        self.to = TimeOut(to_range)\n",
    "        self.rrc = RandomResizeCrop(rrc_range)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        z1 = self.to(self.rrc(x))\n",
    "        z2 = self.to(self.rrc(x))\n",
    "        return z1, z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee92307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XResBlock1d(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1d1 = nn.Conv1d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=(kernel_size-1)//2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channel)\n",
    "        self.conv1d2 = nn.Conv1d(out_channel, out_channel, kernel_size=kernel_size, stride=1, padding=(kernel_size-1)//2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            self.shorcut = nn.Sequential(\n",
    "                nn.AvgPool1d(kernel_size=2, stride=stride, ceil_mode=True),\n",
    "                nn.Conv1d(in_channel, out_channel, kernel_size=1),\n",
    "                nn.BatchNorm1d(out_channel)\n",
    "            )\n",
    "        else:\n",
    "            self.shorcut = nn.Identity()\n",
    "        nn.init.constant_(self.bn2.weight, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.relu(self.bn1(self.conv1d1(x)))\n",
    "        output = self.bn2(self.conv1d2(output))\n",
    "        output += self.shorcut(x)\n",
    "        output = self.relu(output)\n",
    "        return output\n",
    "    \n",
    "class XResNet18(nn.Module):\n",
    "    def __init__(self, in_channel=12, out_channel=64, layers=[2, 2, 2, 2]):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv1d(in_channel, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.stem_pool = nn.MaxPool1d(3,2, padding=1)\n",
    "        \n",
    "        self.block1 = self.make_layer(64, 64, layers[0])\n",
    "        self.block2 = self.make_layer(64, 128, layers[1], stride=2)\n",
    "        self.block3 = self.make_layer(128, 256, layers[2], stride=2)\n",
    "        self.block4 = self.make_layer(256, 512, layers[3], stride=2)\n",
    "        \n",
    "        # Projector\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.projection = nn.Sequential(nn.Linear(512, 2048),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(2048, out_channel))\n",
    "        \n",
    "    def make_layer(self, in_channel, out_channel, n_block, stride=1):\n",
    "        blocks = [XResBlock1d(in_channel, out_channel, stride=stride)]\n",
    "        for _ in range(n_block-1):\n",
    "            blocks.append(XResBlock1d(out_channel, out_channel, stride=1))\n",
    "        return nn.Sequential(*blocks)\n",
    "    \n",
    "    def forward_encoder(self, x):\n",
    "        out = self.stem_pool(self.stem(x))\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.avgpool(out)\n",
    "        return out.squeeze(-1)\n",
    "    \n",
    "    def forward_projection(self, feature):\n",
    "        out = self.projection(feature)\n",
    "        return F.normalize(out, dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature = self.forward_encoder(x)\n",
    "        out = self.forward_projection(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5511b8",
   "metadata": {},
   "source": [
    "Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e4520cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, array):\n",
    "        return torch.from_numpy(array).T.float() # (T, C) -> (C, T)\n",
    "\n",
    "\n",
    "class NormalizeECG:\n",
    "\n",
    "    def __call__(self, sample, eps=1e-7):\n",
    "        mean = sample.mean(dim=0, keepdim=True)\n",
    "        std = sample.std(dim=0, keepdim=True)\n",
    "        result = (sample - mean) / (std + eps)\n",
    "        return result\n",
    "\n",
    "class PadECG:\n",
    "\n",
    "    def __init__(self, pad_to=4096):\n",
    "        self.pad_to = pad_to\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if sample.shape[-1] >= self.pad_to:\n",
    "            return sample[:, :self.pad_to] \n",
    "        else:\n",
    "            padding = (0, self.pad_to - sample.shape[1], 0, 0)\n",
    "            data = F.pad(sample, padding, \"constant\", 0)\n",
    "            return data\n",
    "        \n",
    "class ResizeECG:\n",
    "    def __init__(self, out_size=4096):\n",
    "        self.out_size = out_size\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        if sample.shape[-1] >= self.out_size:\n",
    "            return sample[:, :self.out_size]\n",
    "        else:\n",
    "            resized = F.interpolate(sample.unsqueeze(0), size=self.out_size, mode='linear')\n",
    "            return resized.squeeze()\n",
    "\n",
    "\n",
    "class FolderDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None, min_len=800, upsampling=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder (str): Path to the folder containing the .dat and .hea pairs.\n",
    "        \"\"\"\n",
    "        self.folder = folder\n",
    "        self.min_len = min_len\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.record_paths, self.labels = self.find_records()\n",
    "        self.remove_short()\n",
    "        self.N_pos = sum(np.array(self.labels)==1)\n",
    "        self.N_neg = sum(np.array(self.labels)==0)\n",
    "        if upsampling:\n",
    "            self.upsampling()\n",
    "        \n",
    "    def upsampling(self):\n",
    "        pos_indices = [i for i, label in enumerate(self.labels) if label == 1]\n",
    "        while sum(np.array(self.labels)==1)<sum(np.array(self.labels)==0):\n",
    "            sampled_indice = random.choices(pos_indices)\n",
    "            self.labels.append(1)\n",
    "            self.record_paths.append(self.record_paths[sampled_indice[0]])\n",
    "\n",
    "    def find_records(self):\n",
    "        root = Path(self.folder)\n",
    "\n",
    "        records = []\n",
    "        for p in root.rglob('*.dat'):\n",
    "            p = p.with_suffix('')\n",
    "            header = load_header(p)\n",
    "            label = get_label(header)\n",
    "            records.append([p, label])\n",
    "\n",
    "        paths, labels = zip(*records)\n",
    "        return list(paths), list(labels)\n",
    "\n",
    "\n",
    "    def remove_short(self):\n",
    "        i = 0\n",
    "        while i < len(self.record_paths):\n",
    "            path = self.record_paths[i]\n",
    "            signal, fields = load_signals(str(path))\n",
    "            signal_len = signal.shape[0]\n",
    "            if signal_len < self.min_len:\n",
    "                self.record_paths.pop(i)\n",
    "                self.labels.pop(i)\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.record_paths[idx]\n",
    "        signal, fields = load_signals(record)\n",
    "\n",
    "        if self.transform:\n",
    "            signal = self.transform(signal)\n",
    "\n",
    "        return signal, self.labels[idx]\n",
    "    \n",
    "    def get_weight(self):\n",
    "        return self.N_neg / self.N_pos\n",
    "    \n",
    "    def get_n_pos(self):\n",
    "        return sum(np.array(self.labels)==1)\n",
    "    \n",
    "    def get_n_neg(self):\n",
    "        return sum(np.array(self.labels)==0)\n",
    "    \n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for t in self.transforms:\n",
    "            x = t(x)\n",
    "        return x\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, path, transformation=None, augmentation=None, batchsize=64):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.batchsize = batchsize\n",
    "        self.transformation = transformation\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = FolderDataset(self.path, transform=self.transformation)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9094d0",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c36c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://colab.research.google.com/drive/1UK8BD3xvTpuSj75blz8hThfXksh19YbA?usp=sharing#scrollTo=GBNm6bbDT9J3\n",
    "def nt_xent_loss(out_1, out_2, temperature=0.5, eps=1e-6):\n",
    "    out = torch.cat([out_1, out_2], dim=0)\n",
    "    n_samples = len(out)\n",
    "    \n",
    "    cov = torch.mm(out, out.t().contiguous())\n",
    "    sim = torch.exp(cov / temperature)\n",
    "    \n",
    "    mask = ~torch.eye(n_samples, device=sim.device).bool()\n",
    "    neg = sim.masked_select(mask).view(n_samples, -1).sum(dim=-1)\n",
    "    \n",
    "    # Positive similarity\n",
    "    pos = torch.exp(torch.sum(out_1 * out_2, dim=-1) / temperature)\n",
    "    pos = torch.cat([pos, pos], dim=0)\n",
    "\n",
    "    loss = -torch.log(pos / (neg + eps)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c0984",
   "metadata": {},
   "source": [
    "pl module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84b962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSLModule(pl.LightningModule):\n",
    "    def __init__(self, enconder, loss_fn=None, lr=1e-3, temperature=0.5, epochs=20):\n",
    "        super().__init__()\n",
    "        self.encoder = enconder\n",
    "        self.lr = lr\n",
    "        self.temperature = temperature\n",
    "        self.loss_fn = loss_fn\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x1, _), (x2, _) = self.trainer.datamodule.augmentation((batch))\n",
    "        z1 = self.encoder(x1)\n",
    "        z2 = self.encoder(x2)\n",
    "        loss = self.loss_fn(z1, z2, temperature=self.temperature)\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ac7b7",
   "metadata": {},
   "source": [
    "### Pretrain phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ca3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = Compose([ToTensor(), NormalizeECG(), ResizeECG()])\n",
    "augmentation = RandomTransformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "811d3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr=5e-3\n",
    "out_channel = 256\n",
    "layers = [3, 4,  6, 3]\n",
    "temperature = 0.2\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "501cb863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_callback = ModelCheckpoint(monitor=\"train_loss\", dirpath=\"./\", filename=\"best-checkpoint\")\n",
    "datamodule = DataModule(path=\"./code15_output/\", transformation=transformation, augmentation=augmentation, batchsize=bs)\n",
    "encoder = XResNet18(out_channel=out_channel, layers=layers)\n",
    "model = SSLModule(enconder=encoder, loss_fn=nt_xent_loss, lr=lr, temperature=temperature, epochs=epochs)\n",
    "#logger = CSVLogger(\"./\", name=\"pretrain\")\n",
    "trainer = pl.Trainer(max_epochs=epochs, accelerator='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc84cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type      | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | encoder | XResNet18 | 8.8 M  | train\n",
      "----------------------------------------------\n",
      "8.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 M     Total params\n",
      "35.248    Total estimated model params size (MB)\n",
      "140       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "d:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 312/312 [03:36<00:00,  1.44it/s, v_num=1, train_loss_step=0.639, train_loss_epoch=1.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 312/312 [03:37<00:00,  1.44it/s, v_num=1, train_loss_step=0.639, train_loss_epoch=1.050]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5326fd94",
   "metadata": {},
   "source": [
    "v1: epochs = 50\n",
    "lr=1e-2\n",
    "out_channel = 256\n",
    "layers = [3, 4,  6, 3]\n",
    "temperature = 0.3\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c4802d",
   "metadata": {},
   "source": [
    "v2: epochs = 100\n",
    "lr=5e-3\n",
    "out_channel = 256\n",
    "layers = [3, 4,  6, 3]\n",
    "temperature = 0.2\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e325e1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training loss')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "log = pd.read_csv(\"lightning_logs/version_1/metrics.csv\")\n",
    "log = log[[\"epoch\", \"train_loss_epoch\"]].dropna()\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(log[\"epoch\"], log[\"train_loss_epoch\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.encoder.state_dict(), \"encoder.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ca1e6",
   "metadata": {},
   "source": [
    "### Finetune phase (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0c93650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(pl.LightningModule):\n",
    "    def __init__(self, encoder, out_dim=1, lr=1e-3, epochs=10, pos_weight=1, linear=False, frozen=True):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.lr = lr\n",
    "        if linear:\n",
    "            self.classifier = nn.Linear(512, out_dim)\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(256, out_dim)\n",
    "                )\n",
    "        self.epochs = epochs\n",
    "        self.best_val_loss = 1\n",
    "        self.frozen = frozen \n",
    "        \n",
    "        # Freeze encoder \n",
    "        if self.frozen:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False        \n",
    "            \n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature = self.encoder.forward_encoder(x)\n",
    "        out = self.classifier(feature)\n",
    "        return out.squeeze(-1)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "        loss = self.loss_fn(pred, y.float())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "        loss = self.loss_fn(pred, y.float())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.epochs)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = self.trainer.callback_metrics.get(\"val_loss\")\n",
    "        if loss < self.best_val_loss:\n",
    "            self.best_val_loss = loss\n",
    "            torch.save(self.classifier.state_dict(), \"Best_classifier.pt\")\n",
    "            if not self.frozen:\n",
    "                torch.save(self.encoder.state_dict(), \"Best_encoder.pt\")\n",
    "    \n",
    "class FinetuneDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_path, val_path, transformation=None, augmentation=None, batchsize=64, upsampling=False):\n",
    "        super().__init__()\n",
    "        self.train_path = train_path\n",
    "        self.val_path = val_path\n",
    "        self.batchsize = batchsize\n",
    "        self.transformation = transformation\n",
    "        self.augmentation = augmentation\n",
    "        self.upsampling = upsampling\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = FolderDataset(self.train_path, transform=self.transformation, upsampling=self.upsampling)\n",
    "        self.val_dataset = FolderDataset(self.val_path, transform=self.transformation)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batchsize, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        if self.val_path:\n",
    "            return DataLoader(self.val_dataset, batch_size=self.batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "099d9198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = XResNet18(out_channel=out_channel, layers=layers)\n",
    "encoder.load_state_dict(torch.load(\"encoder_pretrain.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "34cbd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr=5e-4\n",
    "out_dim = 1\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8a3cb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = FinetuneDataModule(train_path=\"./training_data/\", val_path='./val_data/', transformation=transformation, batchsize=bs, upsampling=False)\n",
    "train_loader.setup()\n",
    "pos_weight = train_loader.train_dataset.get_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c2fa299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "classifier = ClassifierModule(encoder=encoder, lr=lr, out_dim = out_dim, epochs=epochs, pos_weight=pos_weight, frozen=False)\n",
    "trainer = pl.Trainer(max_epochs=epochs, accelerator='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "df8c8157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:   3%|▎         | 3/112 [08:02<4:52:11,  0.01it/s, v_num=12, train_loss_step=0.0585, val_loss=0.950, train_loss_epoch=0.0229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | encoder    | XResNet18         | 8.8 M  | train\n",
      "1 | classifier | Sequential        | 131 K  | train\n",
      "2 | loss_fn    | BCEWithLogitsLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "8.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 M     Total params\n",
      "35.774    Total estimated model params size (MB)\n",
      "146       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   9%|▉         | 10/112 [00:05<00:57,  1.76it/s, v_num=14, train_loss_step=0.0961, val_loss=0.620, train_loss_epoch=0.152] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    595\u001b[0m     ckpt_path,\n\u001b[0;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m )\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loop\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher)\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:282\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    281\u001b[0m dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m batch, _, __ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:134\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__next__\u001b[39m()\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:61\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:78\u001b[0m, in \u001b[0;36m_MaxSizeCycle.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterators[i])\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[95], line 98\u001b[0m, in \u001b[0;36mFolderDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 98\u001b[0m     signal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(signal)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signal, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n",
      "Cell \u001b[1;32mIn[4], line 98\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 98\u001b[0m     x \u001b[38;5;241m=\u001b[39m t(x)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, array)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, array):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(array)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(classifier, datamodule\u001b[38;5;241m=\u001b[39mtrain_loader)\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    563\u001b[0m )\n",
      "File \u001b[1;32md:\\Tools\\Anaconda\\envs\\gymenv\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 65\u001b[0m     exit(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(classifier, datamodule=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84ccdb",
   "metadata": {},
   "source": [
    "V2 epochs = 10\n",
    "lr=1e-4\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "no schedular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4a578",
   "metadata": {},
   "source": [
    "V5 epochs = 10\n",
    "lr=5e-4\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "with schedular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb9df4",
   "metadata": {},
   "source": [
    "V6 epochs = 20\n",
    "lr=1e-3\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "with schedular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a927b",
   "metadata": {},
   "source": [
    "V7 epochs = 20\n",
    "lr=1e-3\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "with schedular\n",
    "pos_weight = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c30922",
   "metadata": {},
   "source": [
    "V8 epochs = 20\n",
    "lr=1e-3\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "with schedular\n",
    "upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbb77f",
   "metadata": {},
   "source": [
    "V9 epochs = 10\n",
    "lr=1e-3\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "with schedular\n",
    "upsampling\n",
    "non_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea99ef02",
   "metadata": {},
   "source": [
    "V10 epochs = 20\n",
    "lr=1e-3\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "with schedular\n",
    "weighted\n",
    "non_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1370405",
   "metadata": {},
   "source": [
    "V12 epochs = 20\n",
    "lr=1e-3\n",
    "out_dim = 1\n",
    "bs = 128\n",
    "with schedular\n",
    "weighted\n",
    "non_linear\n",
    "no freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a714a10",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
